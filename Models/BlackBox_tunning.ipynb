{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import timedelta\n",
    "from torch.utils.tensorboard  import SummaryWriter\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "try:\n",
    "  from google.colab import files\n",
    "  from google.colab import drive\n",
    "  uploaded = files.upload()\n",
    "  !mkdir -p \"/content/drive/My Drive/p9\"\n",
    "  drive.mount('/content/drive')\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "import warnings\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        HourUTC     HourDK  MunicipalityNo Branche  \\\n",
      "HourDK                                                               \n",
      "2021-01-08  2021-01-07 23:00:00 2021-01-08             851  Privat   \n",
      "\n",
      "            ConsumptionkWh  ConsumptionkWh_lag1  ConsumptionkWh_lag24  \\\n",
      "HourDK                                                                  \n",
      "2021-01-08       28924.472            33787.185             29444.332   \n",
      "\n",
      "            ConsumptionkWh_lag168  ConsumptionkWh_roll24  \\\n",
      "HourDK                                                     \n",
      "2021-01-08              37842.849           42275.367875   \n",
      "\n",
      "            ConsumptionkWh_roll168  is_holiday  day_of_week  is_weekend  \\\n",
      "HourDK                                                                    \n",
      "2021-01-08            42130.498304       False            4           0   \n",
      "\n",
      "            hour_sin  hour_cos   day_sin   day_cos  month_sin  month_cos  \n",
      "HourDK                                                                    \n",
      "2021-01-08       0.0       1.0 -0.433884 -0.900969        0.5   0.866025  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/ConsumptionIndustry.csv' if not IN_COLAB else 'ConsumptionIndustry.csv', sep=';')\n",
    "\n",
    "df['HourDK'] = pd.to_datetime(df['HourDK'])\n",
    "df['ConsumptionkWh'] = df['ConsumptionkWh'].str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "# Lag features\n",
    "df['ConsumptionkWh_lag1'] = df['ConsumptionkWh'].shift(1)\n",
    "df['ConsumptionkWh_lag24'] = df['ConsumptionkWh'].shift(24)\n",
    "df['ConsumptionkWh_lag168'] = df['ConsumptionkWh'].shift(168)\n",
    "\n",
    "\n",
    "# Rolling Average\n",
    "df['ConsumptionkWh_roll24'] = df['ConsumptionkWh'].rolling(window=24).mean()\n",
    "df['ConsumptionkWh_roll168'] = df['ConsumptionkWh'].rolling(window=168).mean()\n",
    "\n",
    "# Holidays in Denmark from 2021 to 2024 (source: https://publicholidays.dk/)\n",
    "holidays = ['2021-01-01', '2021-04-01', '2021-04-02', '2021-04-05', '2021-05-13', '2021-05-21', '2021-06-01', '2021-06-24', '2021-12-24', '2021-12-25', '2021-12-26', '2021-12-31', '2022-01-01', '2022-04-14', '2022-04-15', '2022-04-18', '2022-05-05', '2022-05-13', '2022-05-26', '2022-06-05', '2022-06-24', '2022-12-24', '2022-12-25', '2022-12-26',\n",
    "            '2022-12-31', '2023-01-01', '2023-03-24', '2023-03-25', '2023-03-26', '2023-04-07', '2023-05-05', '2023-05-13', '2023-05-26', '2023-06-05', '2023-06-24', '2023-12-24', '2023-12-25', '2023-12-26', '2023-12-31', '2024-01-01', '2024-03-28', '2024-03-29', '2024-03-30', '2024-04-05', '2024-05-05', '2024-05-13', '2024-05-26', '2024-06-05', '2024-06-24']\n",
    "holidays = pd.to_datetime(holidays)\n",
    "df['is_holiday'] = df['HourDK'].dt.date.isin(holidays.date)\n",
    "\n",
    "# Weekday and weekend flag\n",
    "df['day_of_week'] = df['HourDK'].dt.dayofweek\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "\n",
    "# Hour of the Day (0-23) to sine/cosine transformation\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['HourDK'].dt.hour / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['HourDK'].dt.hour / 24)\n",
    "\n",
    "# Day of the Week (0-6) to sine/cosine transformation\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "# Month of the Year (1-12) to sine/cosine transformation\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['HourDK'].dt.month / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['HourDK'].dt.month / 12)\n",
    "\n",
    "df.index = df['HourDK']\n",
    "\n",
    "# drop Nan values\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "feature_cols = ['ConsumptionkWh_lag1', 'ConsumptionkWh_lag24', 'ConsumptionkWh_lag168',\n",
    "                'ConsumptionkWh_roll24', 'ConsumptionkWh_roll168', 'hour_sin', 'hour_cos',\n",
    "                'day_sin', 'day_cos', 'month_sin', 'month_cos']\n",
    "target_col = 'ConsumptionkWh'\n",
    "\n",
    "\n",
    "def normalize_dataset(train_df, val_df, test_df):\n",
    "\n",
    "  # Make explicit copies to avoid modifying slices\n",
    "  train_df = train_df.copy()\n",
    "  val_df = val_df.copy()\n",
    "  test_df = test_df.copy()\n",
    "\n",
    "  # Apply scaling to features (.loc for Explicit Indexing)\n",
    "  train_df.loc[:, feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
    "  val_df.loc[:, feature_cols] = scaler.transform(val_df[feature_cols])\n",
    "  test_df.loc[:, feature_cols] = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "  # Apply scaling to the target column\n",
    "  train_df.loc[:, target_col] = scaler.fit_transform(train_df[[target_col]])\n",
    "  val_df.loc[:, target_col] = scaler.transform(val_df[[target_col]])\n",
    "  test_df.loc[:, target_col] = scaler.transform(test_df[[target_col]])\n",
    "\n",
    "  return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "class EnergyDataset(Dataset):\n",
    "  def __init__(self, data, feature_cols, target_col):\n",
    "    self.features = torch.tensor(\n",
    "        data[feature_cols].values, dtype=torch.float32)\n",
    "    self.targets = torch.tensor(data[target_col].values, dtype=torch.float32)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.targets)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.features[idx], self.targets[idx]\n",
    "\n",
    "def create_dataset(train_df, val_df, test_df):\n",
    "  train_dataset = EnergyDataset(train_df, feature_cols, target_col)\n",
    "  val_dataset = EnergyDataset(val_df, feature_cols, target_col)\n",
    "  test_dataset = EnergyDataset(test_df, feature_cols, target_col)\n",
    "\n",
    "  # Create dataloaders\n",
    "  batch_size = 128\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "  return train_loader, val_loader, test_loader\n",
    "  \n",
    "\n",
    "class EnergyTransformer(nn.Module):\n",
    "  def __init__(self, input_size, d_model, nhead, output_size, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout=0.1):\n",
    "    super(EnergyTransformer, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.d_model = d_model\n",
    "    self.embedding = nn.Linear(input_size, d_model)  # Embedding layer\n",
    "    self.positional_encoding = nn.Parameter(torch.zeros(1, 1000, d_model))  # Replace nn.Embedding\n",
    "    # self.positional_encoding = nn.Parameter(torch.zeros(1, 1000, d_model)) # Positional encoding\n",
    "    self.transformer = nn.Transformer(\n",
    "        d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers,\n",
    "        num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout, batch_first=True\n",
    "    )\n",
    "    self.fc_out = nn.Linear(d_model, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.embedding(x) + self.positional_encoding[:, :x.size(1), :]\n",
    "    output = self.transformer(x, x)\n",
    "    return self.fc_out(output[:, -1, :])\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_data(data_train, data_val, data_test, predictions, save_at=''):\n",
    "  plt.figure(figsize=(7, 3))\n",
    "  plt.plot(data_train.index, data_train, label=f'Train ({data_train.index[0]} - {data_train.index[-1]})')\n",
    "  plt.plot(data_val.index, data_val, label=f'Val ({data_val.index[0]} - {data_val.index[-1]})')\n",
    "  plt.plot(data_test.index, data_test, label=f'Test ({data_test.index[0]} - {data_test.index[-1]})')\n",
    "  plt.plot(data_test.index, predictions, label='Prediction')\n",
    "  plt.title('Consumption in danish private households with prediction')\n",
    "  plt.xlabel('Measurements')\n",
    "  plt.ylabel('Power (kW / charger)')\n",
    "  plt.legend()\n",
    "  if save_at:\n",
    "    plt.savefig(save_at)\n",
    "  plt.show()\n",
    "\n",
    "def sample_data_with_train_window(df, start_date, train_window_size):\n",
    "  start_date = datetime.strptime(start_date, '%Y-%m-%d') - timedelta(hours=train_window_size)\n",
    "  end_date = df.index[-1]\n",
    "  return df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "\n",
    "def get_next_window(data, train_window_size, validation_window_size, forecast_horizon):\n",
    "  return data[:train_window_size], data[train_window_size:validation_window_size+train_window_size], data[train_window_size+validation_window_size:train_window_size + forecast_horizon + validation_window_size]\n",
    "\n",
    "\n",
    "\n",
    "# def forecast_whitebox_model(model, forecast_horizon, model_name):\n",
    "#   model_res = model.fit()\n",
    "\n",
    "#   if \"SARIMA\" in model_name and \"STL\" not in model_name:\n",
    "#     return model_res.get_forecast(steps=forecast_horizon).predicted_mean\n",
    "#   else:\n",
    "#     return model_res.forecast(steps=forecast_horizon)\n",
    "\n",
    "\n",
    "def forecast_blackbox_model(model, train_loader, val_loader, test_loader ,num_epochs,):\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  model = model.to(device)\n",
    "\n",
    "  for epochs in range(num_epochs):\n",
    "    model.train() \n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "      features, targets = batch\n",
    "      features, targets = features.to(device), targets.to(device)\n",
    "\n",
    "      # Forward Pass\n",
    "      optimizer.zero_grad()\n",
    "      targets_pred = model(features.unsqueeze(1)) # Add a dummy sequence length dimension\n",
    "      loss = criterion(targets_pred.squeeze(), targets) # Squeeze the output to match the target shape\n",
    "\n",
    "      # Backward Pass\n",
    "      loss.backward()\n",
    "\n",
    "      # Update the weights\n",
    "      optimizer.step()\n",
    "\n",
    "      # Accumulate the loss for monitoring\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      # Calculate the average loss over the entire training data\n",
    "      train_loss /= len(train_loader)\n",
    "\n",
    "      # Validation Loop\n",
    "      model.eval()\n",
    "      val_loss = 0\n",
    "      with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "          features, targets = batch\n",
    "          features, targets = features.to(device), targets.to(device)\n",
    "          targets_pred = model(features.unsqueeze(1))\n",
    "          loss = criterion(targets_pred.squeeze(), targets)\n",
    "          val_loss += loss.item()\n",
    "\n",
    "      val_loss /= len(val_loader)\n",
    "\n",
    "    # Model predictions \n",
    "    model.eval()\n",
    "\n",
    "\n",
    "  # Collect predictions and targets\n",
    "  predictions = []\n",
    "\n",
    "  with torch.no_grad():  # Disable gradient tracking\n",
    "    for batch in test_loader:\n",
    "      inputs, targets = batch  # Get the inputs and targets\n",
    "      inputs, targets = inputs.to(device), targets.to(\n",
    "          device)  # Move to GPU if available\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(inputs.unsqueeze(1))\n",
    "\n",
    "      # Store predictions \n",
    "      predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "  # Convert back from normalized values to real values\n",
    "    predictions = np.array(predictions)  # Convert list to numpy array\n",
    "    predictions_reshaped = predictions.reshape(-1, 1)\n",
    "\n",
    "    # Use the inverse_transform method to unnormalize\n",
    "    predictions = scaler.inverse_transform(predictions_reshaped)\n",
    "\n",
    "  return predictions.flatten().tolist()  \n",
    "\n",
    "\n",
    "def create_result_table(results, columns=[]):\n",
    "  result_table = pd.DataFrame(results)\n",
    "  result_table.columns = columns\n",
    "  result_table = result_table.sort_values(by='rmse', ascending=True).reset_index(drop=True)\n",
    "  return result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def optimize_Theta_model(data_train, data_test, forecast_horizon, model_name):\n",
    "#   results = []\n",
    "#   best_rmse = 0\n",
    "#   p = range(1, 25)\n",
    "#   d = [True, False]\n",
    "#   u = [True, False]\n",
    "#   m = ['additive', 'multiplicative']\n",
    "#   di = [True, False]\n",
    "\n",
    "#   for param in itertools.product(p, d, u, m, di):\n",
    "#     try:\n",
    "#       model = ThetaModel(data_train, period=param[0], deseasonalize=param[1], use_test=param[2], method=param[3], difference=param[4])\n",
    "#     except:\n",
    "#       continue\n",
    "\n",
    "#     predictions = forecast_whitebox_model(model, forecast_horizon, model_name)\n",
    "#     rmse = root_mean_squared_error(data_test, predictions)\n",
    "#     results.append([param, rmse])\n",
    "#     print(f\"{param} - RMSE: {rmse}\")\n",
    "    \n",
    "#     if rmse < best_rmse or best_rmse == 0:\n",
    "#       best_prediction = predictions\n",
    "\n",
    "#   result_table = create_result_table(results, columns=['params', 'rmse'])\n",
    "#   return result_table, best_prediction\n",
    "\n",
    "\n",
    "def optimize_Transformer_model(data_test, train_loader, val_loader, test_loader):\n",
    "  results = []\n",
    "  best_rmse = 0\n",
    "\n",
    "  # Hard coded \n",
    "  input_size = len(feature_cols)\n",
    "  output_size = 1\n",
    "\n",
    "  d = [64, 128, 256]\n",
    "  nhead = [4, 8, 12]\n",
    "  num_encoder_layers = [3, 6, 9]\n",
    "  num_decoder_layers = [3, 6, 9]\n",
    "  dim_feedforward = [256, 512, 1024]\n",
    "  dropout = [0.1, 0.2, 0.3]\n",
    "  num_epochs = [100, 500]\n",
    "\n",
    "  for param in itertools.product(d, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, num_epochs):\n",
    "    model = EnergyTransformer(input_size=input_size, d_model=param[0], nhead=param[1], output_size=output_size, num_encoder_layers=param[2], num_decoder_layers=param[3], dim_feedforward=param[4], dropout=param[5])\n",
    "    predictions = forecast_blackbox_model(model, train_loader, val_loader, test_loader, num_epochs=param[6])\n",
    "    rmse = root_mean_squared_error(data_test['ConsumptionkWh'], predictions)\n",
    "    results.append([param, rmse])\n",
    "    print(f\"{param} - RMSE: {rmse}\")\n",
    "\n",
    "    if rmse < best_rmse or best_rmse == 0:\n",
    "      best_prediction = predictions\n",
    "\n",
    "  result_table = create_result_table(results, columns=['params', 'rmse'])\n",
    "  return result_table, best_prediction\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing through whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4, 3, 3, 256, 0.1, 100) - RMSE: 4550.805668849192\n",
      "(64, 4, 3, 3, 256, 0.1, 500) - RMSE: 2374.364644208935\n",
      "(64, 4, 3, 3, 256, 0.2, 100) - RMSE: 3188.627632871474\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m create_dataset(data_trainN, data_valN, data_testN)\n\u001b[1;32m     21\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m result, pred \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_Transformer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IN_COLAB:\n",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m, in \u001b[0;36moptimize_Transformer_model\u001b[0;34m(data_test, train_loader, val_loader, test_loader)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(d, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, num_epochs):\n\u001b[1;32m     45\u001b[0m   model \u001b[38;5;241m=\u001b[39m EnergyTransformer(input_size\u001b[38;5;241m=\u001b[39minput_size, d_model\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m0\u001b[39m], nhead\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m1\u001b[39m], output_size\u001b[38;5;241m=\u001b[39moutput_size, num_encoder_layers\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m2\u001b[39m], num_decoder_layers\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m3\u001b[39m], dim_feedforward\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m4\u001b[39m], dropout\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m---> 46\u001b[0m   predictions \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_blackbox_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m   rmse \u001b[38;5;241m=\u001b[39m root_mean_squared_error(data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConsumptionkWh\u001b[39m\u001b[38;5;124m'\u001b[39m], predictions)\n\u001b[1;32m     48\u001b[0m   results\u001b[38;5;241m.\u001b[39mappend([param, rmse])\n",
      "Cell \u001b[0;32mIn[5], line 52\u001b[0m, in \u001b[0;36mforecast_blackbox_model\u001b[0;34m(model, train_loader, val_loader, test_loader, num_epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m features, targets \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Forward Pass\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m targets_pred \u001b[38;5;241m=\u001b[39m model(features\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# Add a dummy sequence length dimension\u001b[39;00m\n\u001b[1;32m     54\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(targets_pred\u001b[38;5;241m.\u001b[39msqueeze(), targets) \u001b[38;5;66;03m# Squeeze the output to match the target shape\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/optim/optimizer.py:952\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 952\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'Transformer'\n",
    "date_start = '2023-11-01'\n",
    "# window_train_size = 24*911 #hours (911 days)\n",
    "# window_val_size = 24*123 #hours (123 days)\n",
    "# forecast_horizon = 24*376 #hours (376 days)\n",
    "\n",
    "window_train_size = 24*7*2  # hours (911 days)\n",
    "window_val_size = 24*7 # hours (123 days)\n",
    "forecast_horizon = 24  # hours (376 days)\n",
    "\n",
    "data = sample_data_with_train_window(df, date_start, window_train_size) # start: date_start - window_train_size, end: last date in df\n",
    "data_train, data_val, data_test = get_next_window(data, window_train_size, window_val_size, forecast_horizon)\n",
    "\n",
    "# Ensure dataframes are not empty\n",
    "if data_train.empty or data_val.empty or data_test.empty:\n",
    "  print(\"One of the dataframes (data_train, data_val, data_test) is empty.\")\n",
    "\n",
    "data_trainN, data_valN, data_testN = normalize_dataset(data_train, data_val, data_test)\n",
    "train_loader, val_loader, test_loader = create_dataset(data_trainN, data_valN, data_testN)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "result, pred = optimize_Transformer_model(data_test, train_loader, val_loader, test_loader)\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "  plot_data(data_train, data_test, pred, save_at=f'/content/drive/My Drive/p9/{window_train_size}_{forecast_horizon}_{model_name}.png')\n",
    "  result.to_csv(f'/content/drive/My Drive/p9/{window_train_size}_{forecast_horizon}_{model_name}.csv')\n",
    "else:\n",
    "  plot_data(data_train, data_test, pred,\n",
    "            save_at=f'../Results/BlackBox/Tuning/{window_train_size}_{forecast_horizon}_{model_name}.png')\n",
    "  result.to_csv(f'../Results/BlackBox/Tuning/{window_train_size}_{forecast_horizon}_{model_name}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
