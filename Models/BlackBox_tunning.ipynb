{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import timedelta\n",
    "from torch.utils.tensorboard  import SummaryWriter\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "try:\n",
    "  from google.colab import files\n",
    "  from google.colab import drive\n",
    "  uploaded = files.upload()\n",
    "  !mkdir -p \"/content/drive/My Drive/p9\"\n",
    "  drive.mount('/content/drive')\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "import warnings\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              HourUTC              HourDK  MunicipalityNo  \\\n",
      "HourDK                                                                      \n",
      "2021-01-08 01:00:00  2021-01-08 00:00 2021-01-08 01:00:00             851   \n",
      "\n",
      "                    Branche  ConsumptionkWh  ConsumptionkWh_lag1  \\\n",
      "HourDK                                                             \n",
      "2021-01-08 01:00:00  Privat       26017.693            28924.472   \n",
      "\n",
      "                     ConsumptionkWh_lag24  ConsumptionkWh_lag168  \\\n",
      "HourDK                                                             \n",
      "2021-01-08 01:00:00             26466.212              35086.772   \n",
      "\n",
      "                     ConsumptionkWh_roll24  ConsumptionkWh_roll168  \\\n",
      "HourDK                                                               \n",
      "2021-01-08 01:00:00           42256.679583             42076.51569   \n",
      "\n",
      "                     is_holiday  day_of_week  is_weekend  hour_sin  hour_cos  \\\n",
      "HourDK                                                                         \n",
      "2021-01-08 01:00:00       False            4           0  0.258819  0.965926   \n",
      "\n",
      "                      day_sin   day_cos  month_sin  month_cos  \n",
      "HourDK                                                         \n",
      "2021-01-08 01:00:00 -0.433884 -0.900969        0.5   0.866025  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/ConsumptionIndustry.csv' if not IN_COLAB else 'ConsumptionIndustry.csv', sep=';')\n",
    "\n",
    "df['HourDK'] = pd.to_datetime(df['HourDK'])\n",
    "df['ConsumptionkWh'] = df['ConsumptionkWh'].str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "# Lag features\n",
    "df['ConsumptionkWh_lag1'] = df['ConsumptionkWh'].shift(1)\n",
    "df['ConsumptionkWh_lag24'] = df['ConsumptionkWh'].shift(24)\n",
    "df['ConsumptionkWh_lag168'] = df['ConsumptionkWh'].shift(168)\n",
    "\n",
    "\n",
    "# Rolling Average\n",
    "df['ConsumptionkWh_roll24'] = df['ConsumptionkWh'].rolling(window=24).mean()\n",
    "df['ConsumptionkWh_roll168'] = df['ConsumptionkWh'].rolling(window=168).mean()\n",
    "\n",
    "# Holidays in Denmark from 2021 to 2024 (source: https://publicholidays.dk/)\n",
    "holidays = ['2021-01-01', '2021-04-01', '2021-04-02', '2021-04-05', '2021-05-13', '2021-05-21', '2021-06-01', '2021-06-24', '2021-12-24', '2021-12-25', '2021-12-26', '2021-12-31', '2022-01-01', '2022-04-14', '2022-04-15', '2022-04-18', '2022-05-05', '2022-05-13', '2022-05-26', '2022-06-05', '2022-06-24', '2022-12-24', '2022-12-25', '2022-12-26',\n",
    "            '2022-12-31', '2023-01-01', '2023-03-24', '2023-03-25', '2023-03-26', '2023-04-07', '2023-05-05', '2023-05-13', '2023-05-26', '2023-06-05', '2023-06-24', '2023-12-24', '2023-12-25', '2023-12-26', '2023-12-31', '2024-01-01', '2024-03-28', '2024-03-29', '2024-03-30', '2024-04-05', '2024-05-05', '2024-05-13', '2024-05-26', '2024-06-05', '2024-06-24']\n",
    "holidays = pd.to_datetime(holidays)\n",
    "df['is_holiday'] = df['HourDK'].dt.date.isin(holidays.date)\n",
    "\n",
    "# Weekday and weekend flag\n",
    "df['day_of_week'] = df['HourDK'].dt.dayofweek\n",
    "df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "\n",
    "# Hour of the Day (0-23) to sine/cosine transformation\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['HourDK'].dt.hour / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['HourDK'].dt.hour / 24)\n",
    "\n",
    "# Day of the Week (0-6) to sine/cosine transformation\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "# Month of the Year (1-12) to sine/cosine transformation\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['HourDK'].dt.month / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['HourDK'].dt.month / 12)\n",
    "\n",
    "df.index = df['HourDK']\n",
    "\n",
    "# drop Nan values\n",
    "df = df.dropna()\n",
    "\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "feature_cols = ['ConsumptionkWh_lag1', 'ConsumptionkWh_lag24', 'ConsumptionkWh_lag168',\n",
    "                'ConsumptionkWh_roll24', 'ConsumptionkWh_roll168', 'hour_sin', 'hour_cos',\n",
    "                'day_sin', 'day_cos', 'month_sin', 'month_cos']\n",
    "target_col = 'ConsumptionkWh'\n",
    "\n",
    "\n",
    "def normalize_dataset(train_df, val_df, test_df):\n",
    "\n",
    "  # Make explicit copies to avoid modifying slices\n",
    "  train_df = train_df.copy()\n",
    "  val_df = val_df.copy()\n",
    "  test_df = test_df.copy()\n",
    "\n",
    "  # Apply scaling to features (.loc for Explicit Indexing)\n",
    "  train_df.loc[:, feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
    "  val_df.loc[:, feature_cols] = scaler.transform(val_df[feature_cols])\n",
    "  test_df.loc[:, feature_cols] = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "  # Apply scaling to the target column\n",
    "  train_df.loc[:, target_col] = scaler.fit_transform(train_df[[target_col]])\n",
    "  val_df.loc[:, target_col] = scaler.transform(val_df[[target_col]])\n",
    "  test_df.loc[:, target_col] = scaler.transform(test_df[[target_col]])\n",
    "\n",
    "  return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "class EnergyDataset(Dataset):\n",
    "  def __init__(self, data, feature_cols, target_col):\n",
    "    self.features = torch.tensor(\n",
    "        data[feature_cols].values, dtype=torch.float32)\n",
    "    self.targets = torch.tensor(data[target_col].values, dtype=torch.float32)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.targets)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.features[idx], self.targets[idx]\n",
    "\n",
    "def create_dataset(train_df, val_df, test_df):\n",
    "  train_dataset = EnergyDataset(train_df, feature_cols, target_col)\n",
    "  val_dataset = EnergyDataset(val_df, feature_cols, target_col)\n",
    "  test_dataset = EnergyDataset(test_df, feature_cols, target_col)\n",
    "\n",
    "  # Create dataloaders\n",
    "  batch_size = 128\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "  return train_loader, val_loader, test_loader\n",
    "  \n",
    "\n",
    "class EnergyTransformer(nn.Module):\n",
    "  def __init__(self, input_size, d_model, nhead, output_size, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout=0.1):\n",
    "    super(EnergyTransformer, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.d_model = d_model\n",
    "    self.embedding = nn.Linear(input_size, d_model)  # Embedding layer\n",
    "    self.positional_encoding = nn.Parameter(torch.zeros(1, 1000, d_model))  # Replace nn.Embedding\n",
    "    # self.positional_encoding = nn.Parameter(torch.zeros(1, 1000, d_model)) # Positional encoding\n",
    "    self.transformer = nn.Transformer(\n",
    "        d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers,\n",
    "        num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout, batch_first=True\n",
    "    )\n",
    "    self.fc_out = nn.Linear(d_model, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.embedding(x) + self.positional_encoding[:, :x.size(1), :]\n",
    "    output = self.transformer(x, x)\n",
    "    return self.fc_out(output[:, -1, :])\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_data(data_train, data_val, data_test, predictions, save_at=''):\n",
    "  plt.figure(figsize=(7, 3))\n",
    "  plt.plot(data_train.index, data_train, label=f'Train ({data_train.index[0]} - {data_train.index[-1]})')\n",
    "  plt.plot(data_val.index, data_val, label=f'Val ({data_val.index[0]} - {data_val.index[-1]})')\n",
    "  plt.plot(data_test.index, data_test, label=f'Test ({data_test.index[0]} - {data_test.index[-1]})')\n",
    "  plt.plot(data_test.index, predictions, label='Prediction')\n",
    "  plt.title('Consumption in danish private households with prediction')\n",
    "  plt.xlabel('Measurements')\n",
    "  plt.ylabel('Power (kW / charger)')\n",
    "  plt.legend()\n",
    "  if save_at:\n",
    "    plt.savefig(save_at)\n",
    "  plt.show()\n",
    "\n",
    "def sample_data_with_train_window(df, start_date, train_window_size):\n",
    "  start_date = datetime.strptime(start_date, '%Y-%m-%d') - timedelta(hours=train_window_size)\n",
    "  end_date = df.index[-1]\n",
    "  return df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "\n",
    "def get_next_window(data, train_window_size, validation_window_size, forecast_horizon):\n",
    "  return data[:train_window_size], data[train_window_size:validation_window_size+train_window_size], data[train_window_size+validation_window_size:train_window_size + forecast_horizon + validation_window_size]\n",
    "\n",
    "\n",
    "\n",
    "# def forecast_whitebox_model(model, forecast_horizon, model_name):\n",
    "#   model_res = model.fit()\n",
    "\n",
    "#   if \"SARIMA\" in model_name and \"STL\" not in model_name:\n",
    "#     return model_res.get_forecast(steps=forecast_horizon).predicted_mean\n",
    "#   else:\n",
    "#     return model_res.forecast(steps=forecast_horizon)\n",
    "\n",
    "\n",
    "def forecast_blackbox_model(model, train_loader, val_loader, test_loader ,num_epochs,):\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  model = model.to(device)\n",
    "\n",
    "  for epochs in range(num_epochs):\n",
    "    model.train() \n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "      features, targets = batch\n",
    "      features, targets = features.to(device), targets.to(device)\n",
    "\n",
    "      # Forward Pass\n",
    "      optimizer.zero_grad()\n",
    "      targets_pred = model(features.unsqueeze(1)) # Add a dummy sequence length dimension\n",
    "      loss = criterion(targets_pred.squeeze(), targets) # Squeeze the output to match the target shape\n",
    "\n",
    "      # Backward Pass\n",
    "      loss.backward()\n",
    "\n",
    "      # Update the weights\n",
    "      optimizer.step()\n",
    "\n",
    "      # Accumulate the loss for monitoring\n",
    "      train_loss += loss.item()\n",
    "\n",
    "      # Calculate the average loss over the entire training data\n",
    "      train_loss /= len(train_loader)\n",
    "\n",
    "      # Validation Loop\n",
    "      model.eval()\n",
    "      val_loss = 0\n",
    "      with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "          features, targets = batch\n",
    "          features, targets = features.to(device), targets.to(device)\n",
    "          targets_pred = model(features.unsqueeze(1))\n",
    "          loss = criterion(targets_pred.squeeze(), targets)\n",
    "          val_loss += loss.item()\n",
    "\n",
    "      val_loss /= len(val_loader)\n",
    "\n",
    "    # Model predictions \n",
    "    model.eval()\n",
    "\n",
    "\n",
    "  # Collect predictions and targets\n",
    "  predictions = []\n",
    "\n",
    "  with torch.no_grad():  # Disable gradient tracking\n",
    "    for batch in test_loader:\n",
    "      inputs, targets = batch  # Get the inputs and targets\n",
    "      inputs, targets = inputs.to(device), targets.to(\n",
    "          device)  # Move to GPU if available\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(inputs.unsqueeze(1))\n",
    "\n",
    "      # Store predictions \n",
    "      predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "  # Convert back from normalized values to real values\n",
    "    predictions = np.array(predictions)  # Convert list to numpy array\n",
    "    predictions_reshaped = predictions.reshape(-1, 1)\n",
    "\n",
    "    # Use the inverse_transform method to unnormalize\n",
    "    predictions = scaler.inverse_transform(predictions_reshaped)\n",
    "\n",
    "  return predictions.flatten().tolist()  \n",
    "\n",
    "\n",
    "def create_result_table(results, columns=[]):\n",
    "  result_table = pd.DataFrame(results)\n",
    "  result_table.columns = columns\n",
    "  result_table = result_table.sort_values(by='rmse', ascending=True).reset_index(drop=True)\n",
    "  return result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def optimize_Theta_model(data_train, data_test, forecast_horizon, model_name):\n",
    "#   results = []\n",
    "#   best_rmse = 0\n",
    "#   p = range(1, 25)\n",
    "#   d = [True, False]\n",
    "#   u = [True, False]\n",
    "#   m = ['additive', 'multiplicative']\n",
    "#   di = [True, False]\n",
    "\n",
    "#   for param in itertools.product(p, d, u, m, di):\n",
    "#     try:\n",
    "#       model = ThetaModel(data_train, period=param[0], deseasonalize=param[1], use_test=param[2], method=param[3], difference=param[4])\n",
    "#     except:\n",
    "#       continue\n",
    "\n",
    "#     predictions = forecast_whitebox_model(model, forecast_horizon, model_name)\n",
    "#     rmse = root_mean_squared_error(data_test, predictions)\n",
    "#     results.append([param, rmse])\n",
    "#     print(f\"{param} - RMSE: {rmse}\")\n",
    "    \n",
    "#     if rmse < best_rmse or best_rmse == 0:\n",
    "#       best_prediction = predictions\n",
    "\n",
    "#   result_table = create_result_table(results, columns=['params', 'rmse'])\n",
    "#   return result_table, best_prediction\n",
    "\n",
    "\n",
    "def optimize_Transformer_model(data_test, train_loader, val_loader, test_loader):\n",
    "  results = []\n",
    "  best_rmse = 0\n",
    "\n",
    "  # Hard coded \n",
    "  input_size = len(feature_cols)\n",
    "  output_size = 1\n",
    "\n",
    "  d = [64, 128, 256]\n",
    "  nhead = [4, 8, 12]\n",
    "  num_encoder_layers = [3, 6, 9]\n",
    "  num_decoder_layers = [3, 6, 9]\n",
    "  dim_feedforward = [256, 512, 1024]\n",
    "  dropout = [0.1, 0.2, 0.3]\n",
    "  num_epochs = [100, 500]\n",
    "\n",
    "  for param in itertools.product(d, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, num_epochs):\n",
    "    model = EnergyTransformer(input_size=input_size, d_model=param[0], nhead=param[1], output_size=output_size, num_encoder_layers=param[2], num_decoder_layers=param[3], dim_feedforward=param[4], dropout=param[5])\n",
    "    predictions = forecast_blackbox_model(model, train_loader, val_loader, test_loader, num_epochs=param[6])\n",
    "    rmse = root_mean_squared_error(data_test['ConsumptionkWh'], predictions)\n",
    "    results.append([param, rmse])\n",
    "    print(f\"{param} - RMSE: {rmse}\")\n",
    "\n",
    "    if rmse < best_rmse or best_rmse == 0:\n",
    "      best_prediction = predictions\n",
    "\n",
    "  result_table = create_result_table(results, columns=['params', 'rmse'])\n",
    "  return result_table, best_prediction\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing through whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4, 3, 3, 256, 0.1, 100) - RMSE: 3042.628412756393\n",
      "(64, 4, 3, 3, 256, 0.1, 500) - RMSE: 2262.2789961079648\n",
      "(64, 4, 3, 3, 256, 0.2, 100) - RMSE: 3178.382955111374\n",
      "(64, 4, 3, 3, 256, 0.2, 500) - RMSE: 1773.0049477997534\n",
      "(64, 4, 3, 3, 256, 0.3, 100) - RMSE: 2465.189391158132\n",
      "(64, 4, 3, 3, 256, 0.3, 500) - RMSE: 1870.1759539668703\n",
      "(64, 4, 3, 3, 512, 0.1, 100) - RMSE: 2101.2775197683936\n",
      "(64, 4, 3, 3, 512, 0.1, 500) - RMSE: 2035.559840240895\n",
      "(64, 4, 3, 3, 512, 0.2, 100) - RMSE: 3673.4931516157358\n",
      "(64, 4, 3, 3, 512, 0.2, 500) - RMSE: 3210.50651141151\n",
      "(64, 4, 3, 3, 512, 0.3, 100) - RMSE: 3208.6448197293616\n",
      "(64, 4, 3, 3, 512, 0.3, 500) - RMSE: 2543.084843008216\n",
      "(64, 4, 3, 3, 1024, 0.1, 100) - RMSE: 4136.503761743903\n",
      "(64, 4, 3, 3, 1024, 0.1, 500) - RMSE: 2107.9197987992716\n",
      "(64, 4, 3, 3, 1024, 0.2, 100) - RMSE: 3059.9290964845377\n",
      "(64, 4, 3, 3, 1024, 0.2, 500) - RMSE: 1591.0505015945578\n",
      "(64, 4, 3, 3, 1024, 0.3, 100) - RMSE: 2707.266528096446\n",
      "(64, 4, 3, 3, 1024, 0.3, 500) - RMSE: 1637.6995486016633\n",
      "(64, 4, 3, 6, 256, 0.1, 100) - RMSE: 2222.878633142448\n",
      "(64, 4, 3, 6, 256, 0.1, 500) - RMSE: 5348.263567447832\n",
      "(64, 4, 3, 6, 256, 0.2, 100) - RMSE: 2811.1359661958204\n",
      "(64, 4, 3, 6, 256, 0.2, 500) - RMSE: 2159.4462367588176\n",
      "(64, 4, 3, 6, 256, 0.3, 100) - RMSE: 2884.109088595734\n",
      "(64, 4, 3, 6, 256, 0.3, 500) - RMSE: 3824.8525589142564\n",
      "(64, 4, 3, 6, 512, 0.1, 100) - RMSE: 4356.784341082181\n",
      "(64, 4, 3, 6, 512, 0.1, 500) - RMSE: 2600.6207796463023\n",
      "(64, 4, 3, 6, 512, 0.2, 100) - RMSE: 3954.8596758582144\n",
      "(64, 4, 3, 6, 512, 0.2, 500) - RMSE: 3544.1399465682352\n",
      "(64, 4, 3, 6, 512, 0.3, 100) - RMSE: 4089.673262351549\n",
      "(64, 4, 3, 6, 512, 0.3, 500) - RMSE: 2875.3383979489217\n",
      "(64, 4, 3, 6, 1024, 0.1, 100) - RMSE: 2414.399832711353\n",
      "(64, 4, 3, 6, 1024, 0.1, 500) - RMSE: 2075.941260136029\n",
      "(64, 4, 3, 6, 1024, 0.2, 100) - RMSE: 1926.136901060095\n",
      "(64, 4, 3, 6, 1024, 0.2, 500) - RMSE: 2077.9421750468005\n",
      "(64, 4, 3, 6, 1024, 0.3, 100) - RMSE: 2809.2620847824683\n",
      "(64, 4, 3, 6, 1024, 0.3, 500) - RMSE: 2720.651763722309\n",
      "(64, 4, 3, 9, 256, 0.1, 100) - RMSE: 1869.8733819206784\n",
      "(64, 4, 3, 9, 256, 0.1, 500) - RMSE: 2408.6018186042884\n",
      "(64, 4, 3, 9, 256, 0.2, 100) - RMSE: 2675.4841426000135\n",
      "(64, 4, 3, 9, 256, 0.2, 500) - RMSE: 2419.3233154970817\n",
      "(64, 4, 3, 9, 256, 0.3, 100) - RMSE: 2004.6916494934871\n",
      "(64, 4, 3, 9, 256, 0.3, 500) - RMSE: 3663.8142155496344\n",
      "(64, 4, 3, 9, 512, 0.1, 100) - RMSE: 1828.3662617768068\n",
      "(64, 4, 3, 9, 512, 0.1, 500) - RMSE: 2301.9642140860165\n",
      "(64, 4, 3, 9, 512, 0.2, 100) - RMSE: 2432.95854572243\n",
      "(64, 4, 3, 9, 512, 0.2, 500) - RMSE: 1910.6466292230705\n",
      "(64, 4, 3, 9, 512, 0.3, 100) - RMSE: 3279.4636684612333\n",
      "(64, 4, 3, 9, 512, 0.3, 500) - RMSE: 2417.367314508064\n",
      "(64, 4, 3, 9, 1024, 0.1, 100) - RMSE: 2205.1264258587657\n",
      "(64, 4, 3, 9, 1024, 0.1, 500) - RMSE: 2431.3304753629104\n",
      "(64, 4, 3, 9, 1024, 0.2, 100) - RMSE: 4582.284950542248\n",
      "(64, 4, 3, 9, 1024, 0.2, 500) - RMSE: 2621.7536707877357\n",
      "(64, 4, 3, 9, 1024, 0.3, 100) - RMSE: 2569.5115880334183\n",
      "(64, 4, 3, 9, 1024, 0.3, 500) - RMSE: 2239.5542603202234\n",
      "(64, 4, 6, 3, 256, 0.1, 100) - RMSE: 4710.993902289053\n",
      "(64, 4, 6, 3, 256, 0.1, 500) - RMSE: 3560.3701969499557\n",
      "(64, 4, 6, 3, 256, 0.2, 100) - RMSE: 2365.8195142420936\n",
      "(64, 4, 6, 3, 256, 0.2, 500) - RMSE: 2690.831160802571\n",
      "(64, 4, 6, 3, 256, 0.3, 100) - RMSE: 3690.9992035540504\n",
      "(64, 4, 6, 3, 256, 0.3, 500) - RMSE: 1823.0115795826703\n",
      "(64, 4, 6, 3, 512, 0.1, 100) - RMSE: 3549.1704311992103\n",
      "(64, 4, 6, 3, 512, 0.1, 500) - RMSE: 1959.9914643945017\n",
      "(64, 4, 6, 3, 512, 0.2, 100) - RMSE: 2820.311497326761\n",
      "(64, 4, 6, 3, 512, 0.2, 500) - RMSE: 3181.9109113932373\n",
      "(64, 4, 6, 3, 512, 0.3, 100) - RMSE: 4064.0132425244674\n",
      "(64, 4, 6, 3, 512, 0.3, 500) - RMSE: 1803.8144434734002\n",
      "(64, 4, 6, 3, 1024, 0.1, 100) - RMSE: 2521.1859731230443\n",
      "(64, 4, 6, 3, 1024, 0.1, 500) - RMSE: 2311.162334865907\n",
      "(64, 4, 6, 3, 1024, 0.2, 100) - RMSE: 2452.0850682418713\n",
      "(64, 4, 6, 3, 1024, 0.2, 500) - RMSE: 1882.658194911432\n",
      "(64, 4, 6, 3, 1024, 0.3, 100) - RMSE: 2776.883883346534\n",
      "(64, 4, 6, 3, 1024, 0.3, 500) - RMSE: 2950.1678193205184\n",
      "(64, 4, 6, 6, 256, 0.1, 100) - RMSE: 1867.8234910989574\n",
      "(64, 4, 6, 6, 256, 0.1, 500) - RMSE: 3372.996148789041\n",
      "(64, 4, 6, 6, 256, 0.2, 100) - RMSE: 2637.507102870169\n",
      "(64, 4, 6, 6, 256, 0.2, 500) - RMSE: 4819.5354409411975\n",
      "(64, 4, 6, 6, 256, 0.3, 100) - RMSE: 2215.785127353704\n",
      "(64, 4, 6, 6, 256, 0.3, 500) - RMSE: 1633.7829440462208\n",
      "(64, 4, 6, 6, 512, 0.1, 100) - RMSE: 2651.2791212861002\n",
      "(64, 4, 6, 6, 512, 0.1, 500) - RMSE: 3064.207245829476\n",
      "(64, 4, 6, 6, 512, 0.2, 100) - RMSE: 3654.5023984402405\n",
      "(64, 4, 6, 6, 512, 0.2, 500) - RMSE: 2061.669897994983\n",
      "(64, 4, 6, 6, 512, 0.3, 100) - RMSE: 3436.4797754553665\n",
      "(64, 4, 6, 6, 512, 0.3, 500) - RMSE: 3071.308119521412\n",
      "(64, 4, 6, 6, 1024, 0.1, 100) - RMSE: 3054.2520190072687\n",
      "(64, 4, 6, 6, 1024, 0.1, 500) - RMSE: 1519.3716233342236\n",
      "(64, 4, 6, 6, 1024, 0.2, 100) - RMSE: 2054.206867677395\n",
      "(64, 4, 6, 6, 1024, 0.2, 500) - RMSE: 4087.639181751618\n",
      "(64, 4, 6, 6, 1024, 0.3, 100) - RMSE: 2105.7972831195275\n",
      "(64, 4, 6, 6, 1024, 0.3, 500) - RMSE: 1771.509133484676\n",
      "(64, 4, 6, 9, 256, 0.1, 100) - RMSE: 3787.862983483747\n",
      "(64, 4, 6, 9, 256, 0.1, 500) - RMSE: 3497.07324120865\n",
      "(64, 4, 6, 9, 256, 0.2, 100) - RMSE: 3121.3289424491827\n",
      "(64, 4, 6, 9, 256, 0.2, 500) - RMSE: 2214.4822515927444\n",
      "(64, 4, 6, 9, 256, 0.3, 100) - RMSE: 3181.3484675699174\n",
      "(64, 4, 6, 9, 256, 0.3, 500) - RMSE: 2512.4408536623323\n",
      "(64, 4, 6, 9, 512, 0.1, 100) - RMSE: 3107.189740674269\n",
      "(64, 4, 6, 9, 512, 0.1, 500) - RMSE: 1856.6932418809943\n",
      "(64, 4, 6, 9, 512, 0.2, 100) - RMSE: 5812.00457488213\n",
      "(64, 4, 6, 9, 512, 0.2, 500) - RMSE: 2780.1324123453182\n",
      "(64, 4, 6, 9, 512, 0.3, 100) - RMSE: 3596.3750719344926\n",
      "(64, 4, 6, 9, 512, 0.3, 500) - RMSE: 2070.8344998092643\n",
      "(64, 4, 6, 9, 1024, 0.1, 100) - RMSE: 2270.775757982631\n",
      "(64, 4, 6, 9, 1024, 0.1, 500) - RMSE: 1931.9828247349021\n",
      "(64, 4, 6, 9, 1024, 0.2, 100) - RMSE: 2202.413026592977\n",
      "(64, 4, 6, 9, 1024, 0.2, 500) - RMSE: 1414.1926279121215\n",
      "(64, 4, 6, 9, 1024, 0.3, 100) - RMSE: 4260.315973906711\n",
      "(64, 4, 6, 9, 1024, 0.3, 500) - RMSE: 4984.706747183287\n",
      "(64, 4, 9, 3, 256, 0.1, 100) - RMSE: 2180.6515364655174\n",
      "(64, 4, 9, 3, 256, 0.1, 500) - RMSE: 1613.9229362496935\n",
      "(64, 4, 9, 3, 256, 0.2, 100) - RMSE: 2275.36108147882\n",
      "(64, 4, 9, 3, 256, 0.2, 500) - RMSE: 2780.2466331276482\n",
      "(64, 4, 9, 3, 256, 0.3, 100) - RMSE: 6100.666478877326\n",
      "(64, 4, 9, 3, 256, 0.3, 500) - RMSE: 2933.230807371844\n",
      "(64, 4, 9, 3, 512, 0.1, 100) - RMSE: 2341.635161127279\n",
      "(64, 4, 9, 3, 512, 0.1, 500) - RMSE: 1797.1876619153163\n",
      "(64, 4, 9, 3, 512, 0.2, 100) - RMSE: 4095.176633836914\n",
      "(64, 4, 9, 3, 512, 0.2, 500) - RMSE: 2732.8816669815665\n",
      "(64, 4, 9, 3, 512, 0.3, 100) - RMSE: 3481.6987448121904\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[221], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m create_dataset(data_trainN, data_valN, data_testN)\n\u001b[1;32m     21\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m result, pred \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_Transformer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IN_COLAB:\n",
      "Cell \u001b[0;32mIn[220], line 46\u001b[0m, in \u001b[0;36moptimize_Transformer_model\u001b[0;34m(data_test, train_loader, val_loader, test_loader)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mproduct(d, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, num_epochs):\n\u001b[1;32m     45\u001b[0m   model \u001b[38;5;241m=\u001b[39m EnergyTransformer(input_size\u001b[38;5;241m=\u001b[39minput_size, d_model\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m0\u001b[39m], nhead\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m1\u001b[39m], output_size\u001b[38;5;241m=\u001b[39moutput_size, num_encoder_layers\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m2\u001b[39m], num_decoder_layers\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m3\u001b[39m], dim_feedforward\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m4\u001b[39m], dropout\u001b[38;5;241m=\u001b[39mparam[\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m---> 46\u001b[0m   predictions \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_blackbox_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m   rmse \u001b[38;5;241m=\u001b[39m root_mean_squared_error(data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConsumptionkWh\u001b[39m\u001b[38;5;124m'\u001b[39m], predictions)\n\u001b[1;32m     48\u001b[0m   results\u001b[38;5;241m.\u001b[39mappend([param, rmse])\n",
      "Cell \u001b[0;32mIn[219], line 53\u001b[0m, in \u001b[0;36mforecast_blackbox_model\u001b[0;34m(model, train_loader, val_loader, test_loader, num_epochs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Forward Pass\u001b[39;00m\n\u001b[1;32m     52\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 53\u001b[0m targets_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Add a dummy sequence length dimension\u001b[39;00m\n\u001b[1;32m     54\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(targets_pred\u001b[38;5;241m.\u001b[39msqueeze(), targets) \u001b[38;5;66;03m# Squeeze the output to match the target shape\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Backward Pass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[218], line 71\u001b[0m, in \u001b[0;36mEnergyTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     70\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding[:, :x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), :]\n\u001b[0;32m---> 71\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/transformer.py:272\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     )\n\u001b[0;32m--> 272\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m    279\u001b[0m     tgt,\n\u001b[1;32m    280\u001b[0m     memory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal,\n\u001b[1;32m    287\u001b[0m )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/transformer.py:511\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    508\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 511\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    519\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/transformer.py:906\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m    903\u001b[0m         x\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m    905\u001b[0m     )\n\u001b[0;32m--> 906\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/transformer.py:931\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 931\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = 'Transformer'\n",
    "date_start = '2023-11-01'\n",
    "# window_train_size = 24*911 #hours (911 days)\n",
    "# window_val_size = 24*123 #hours (123 days)\n",
    "# forecast_horizon = 24*376 #hours (376 days)\n",
    "\n",
    "window_train_size = 24*7*2  # hours (911 days)\n",
    "window_val_size = 24*7 # hours (123 days)\n",
    "forecast_horizon = 24  # hours (376 days)\n",
    "\n",
    "data = sample_data_with_train_window(df, date_start, window_train_size) # start: date_start - window_train_size, end: last date in df\n",
    "data_train, data_val, data_test = get_next_window(data, window_train_size, window_val_size, forecast_horizon)\n",
    "\n",
    "# Ensure dataframes are not empty\n",
    "if data_train.empty or data_val.empty or data_test.empty:\n",
    "  print(\"One of the dataframes (data_train, data_val, data_test) is empty.\")\n",
    "\n",
    "data_trainN, data_valN, data_testN = normalize_dataset(data_train, data_val, data_test)\n",
    "train_loader, val_loader, test_loader = create_dataset(data_trainN, data_valN, data_testN)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "result, pred = optimize_Transformer_model(data_test, train_loader, val_loader, test_loader)\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "  plot_data(data_train, data_test, pred, save_at=f'/content/drive/My Drive/p9/{window_train_size}_{forecast_horizon}_{model_name}.png')\n",
    "  result.to_csv(f'/content/drive/My Drive/p9/{window_train_size}_{forecast_horizon}_{model_name}.csv')\n",
    "else:\n",
    "  plot_data(data_train, data_test, pred, save_at=f'../Results/Whitebox/Tuning/{window_train_size}_{forecast_horizon}_{model_name}.png')\n",
    "  result.to_csv(f'../Results/Whitebox/Tuning/{window_train_size}_{forecast_horizon}_{model_name}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
