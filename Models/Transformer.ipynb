{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTx-YbEakTu2"
      },
      "source": [
        "# Transformer (DTU DATA)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Needed for Google CoLab"
      ],
      "metadata": {
        "id": "vJQqA__QkzXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To run on Colab, you need to run this code\n",
        "!pip install torch torchvision torchaudio pandas numpy scikit-learn"
      ],
      "metadata": {
        "id": "udsbROu6kbHb",
        "outputId": "d583aae2-f82f-4c48-f966-3a56281eeaf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "abtXvlQHk7ZG",
        "outputId": "8a3f738f-ee7e-4bab-8324-f233edfd6827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c2e7e707-476b-48c8-b852-ecd69242e14e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c2e7e707-476b-48c8-b852-ecd69242e14e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving AveragePower.xlsx to AveragePower.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi1fjVT9kTu3"
      },
      "source": [
        "## Importing Excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LiPzUbxckTu3",
        "outputId": "6063b933-84fd-47b6-d9ee-f9c824e4da24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2022 Data\n",
            "   Year  Month  Hour  DayType     power\n",
            "0  2022      1     0  Weekday  0.943937\n",
            "1  2022      1     1  Weekday  0.955728\n",
            "2  2022      1     2  Weekday  0.772173\n",
            "3  2022      1     3  Weekday  0.530580\n",
            "4  2022      1     4  Weekday  0.333006\n",
            "   Year  Month  Hour  DayType     power\n",
            "0  2022      1     0  Weekend  0.680075\n",
            "1  2022      1     1  Weekend  0.739797\n",
            "2  2022      1     2  Weekend  0.605256\n",
            "3  2022      1     3  Weekend  0.440174\n",
            "4  2022      1     4  Weekend  0.310420\n",
            "\n",
            "2023 Data\n",
            "   Year  Month  Hour  DayType     power\n",
            "0  2023      1     0  Weekday  0.881067\n",
            "1  2023      1     1  Weekday  1.288525\n",
            "2  2023      1     2  Weekday  1.312552\n",
            "3  2023      1     3  Weekday  1.074686\n",
            "4  2023      1     4  Weekday  0.573104\n",
            "   Year  Month  Hour  DayType     power\n",
            "0  2023      1     0  Weekend  0.805268\n",
            "1  2023      1     1  Weekend  1.142235\n",
            "2  2023      1     2  Weekend  1.186799\n",
            "3  2023      1     3  Weekend  1.097171\n",
            "4  2023      1     4  Weekend  0.780017\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the dataset\n",
        "#df = pd.read_excel('../Dataset/AveragePower.xlsx')\n",
        "df = pd.read_excel('AveragePower.xlsx')\n",
        "\n",
        "\n",
        "# Split the data into 2022 and 2023 based on the 'Year' column\n",
        "df_2022 = df[df['Year'] == 2022].reset_index(drop=True)\n",
        "df_2023 = df[df['Year'] == 2023].reset_index(drop=True)\n",
        "\n",
        "# Split the 2022 and 2023 data by 'DayType' (Weekday, Weekend)\n",
        "df_2022_weekday = df_2022[df_2022['DayType'] == 'Weekday'].reset_index(drop=True)\n",
        "df_2022_weekend = df_2022[df_2022['DayType'] == 'Weekend'].reset_index(drop=True)\n",
        "df_2023_weekday = df_2023[df_2023['DayType'] == 'Weekday'].reset_index(drop=True)\n",
        "df_2023_weekend = df_2023[df_2023['DayType'] == 'Weekend'].reset_index(drop=True)\n",
        "\n",
        "print(\"\\n2022 Data\");\n",
        "print(df_2022_weekday.head())\n",
        "print(df_2022_weekend.head())\n",
        "\n",
        "print(\"\\n2023 Data\")\n",
        "print(df_2023_weekday.head())\n",
        "print(df_2023_weekend.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1z3fdukkTu5"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PplE8MOxkTu5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def preprocess_data(df):\n",
        "  # Encode 'Hour' using sine and cosine\n",
        "  df['Hour_sin'] = np.sin(2 * np.pi * df['Hour']/24)\n",
        "  df['Hour_cos'] = np.cos(2 * np.pi * df['Hour']/24)\n",
        "\n",
        "  # Encode 'month' using sine and cosine\n",
        "  df['Month_sin'] = np.sin(2 * np.pi * df['Month']/12)\n",
        "  df['Month_cos'] = np.cos(2 * np.pi * df['Month']/12)\n",
        "\n",
        "  # Scale 'Power' using StandardScaler\n",
        "  scaler = StandardScaler()\n",
        "  df['Power'] = scaler.fit_transform(df[['power']])\n",
        "\n",
        "  return df, scaler\n",
        "\n",
        "# Proprocess Weekday data and Weekend data for 2022\n",
        "df_2022_weekday, scaler_weekday = preprocess_data(df_2022_weekday)\n",
        "df_2022_weekend, scaler_weekend = preprocess_data(df_2022_weekend)\n",
        "\n",
        "# Proprocess Weekday data and Weekend data for 2023\n",
        "df_2023_weekday, _ = preprocess_data(df_2023_weekday)\n",
        "df_2023_weekend, _ = preprocess_data(df_2023_weekend)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIz6gQ5YkTu6"
      },
      "source": [
        "## Squence Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yVTQXRAhkTu6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Function to create sequences for the model\n",
        "def create_sequences(df, window_size):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    # Ensure that the data is numeric before processing\n",
        "    # Convert all columns to numeric\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    for i in range(len(df) - window_size):\n",
        "        # Drop power column for features\n",
        "        seq = df.iloc[i:i + window_size].drop(columns=['Power']).values\n",
        "        # Target is the next hour's power value\n",
        "        label = df.iloc[i + window_size]['Power']\n",
        "        sequences.append(seq)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(sequences), np.array(labels)\n",
        "\n",
        "# Create sequences for a month (24 hours)\n",
        "sequence_length = 24\n",
        "\n",
        "# Create sequences for Weekday and Weekend data\n",
        "X_train_weekday, y_train_weekday = create_sequences(\n",
        "    df_2022_weekday, sequence_length)\n",
        "X_train_weekday = X_train_weekday.astype(np.float32)  # Ensure float32\n",
        "X_train_weekday = torch.tensor(X_train_weekday, dtype=torch.float32)\n",
        "X_train_weekday = np.nan_to_num(X_train_weekday, nan=0.0).astype(np.float32)\n",
        "X_train_weekend, y_train_weekend = create_sequences(df_2022_weekend, sequence_length)\n",
        "\n",
        "\n",
        "X_test_weekday, y_test_weekday = create_sequences(df_2023_weekday, sequence_length)\n",
        "X_test_weekend, y_test_weekend = create_sequences(df_2023_weekend, sequence_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btJefq-rkTu6"
      },
      "source": [
        "# Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8VxPHYnakTu6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PowerPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, nhead, num_layers, output_dim):\n",
        "        super(PowerPredictor, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.num_layers = num_layers\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        # Ensure input features match d_model\n",
        "        # Map input features to d_model\n",
        "        self.fc_input = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        # Transformer model\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model, nhead=nhead, num_encoder_layers=num_layers)\n",
        "\n",
        "        # Fully connected layer for output\n",
        "        self.fc = nn.Linear(d_model, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply fully connected layer to match input to d_model\n",
        "        # (batch_size, seq_len, input_dim) -> (batch_size, seq_len, d_model)\n",
        "        x = self.fc_input(x)\n",
        "\n",
        "        # Transformer expects input shape (seq_len, batch_size, feature_dim)\n",
        "        # (batch_size, seq_len, feature_dim) -> (seq_len, batch_size, feature_dim)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        transformer_output = self.transformer(x, x)\n",
        "        # Use the last output to predict next value\n",
        "        out = self.fc(transformer_output[-1])\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQH8-RmpkTu7"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OvcznA5IkTu7",
        "outputId": "d8a8fffa-2aa5-4e7a-f8ba-15a4ee3ab9e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 1.2158\n",
            "Epoch [20/50], Loss: 1.0185\n",
            "Epoch [30/50], Loss: 1.0045\n",
            "Epoch [40/50], Loss: 1.0364\n",
            "Epoch [50/50], Loss: 0.9996\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = X_train_weekday.shape[2]  # Number of features (e.g., Hour, Month)\n",
        "d_model = 128  # Transformer model dimension\n",
        "nhead = 4  # Number of heads in MultiheadAttention\n",
        "num_layers = 2  # Number of Transformer layers\n",
        "output_dim = 1  # Single output value\n",
        "\n",
        "# Create model\n",
        "model_weekend = PowerPredictor(\n",
        "    input_dim, d_model, nhead, num_layers, output_dim)\n",
        "\n",
        "\n",
        "# Check data types and handle missing values\n",
        "assert X_train_weekday.dtype in [\n",
        "    np.float32, np.float64], \"X_train_weekday must be float32 or float64\"\n",
        "assert y_train_weekday.dtype in [\n",
        "    np.float32, np.float64], \"y_train_weekday must be float32 or float64\"\n",
        "\n",
        "X_train_weekday = np.nan_to_num(X_train_weekday, nan=0.0).astype(np.float32)\n",
        "y_train_weekday = y_train_weekday.astype(np.float32)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_weekday_tensor = torch.tensor(X_train_weekday, dtype=torch.float32)\n",
        "y_train_weekday_tensor = torch.tensor(y_train_weekday, dtype=torch.float32)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model_weekend.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model_weekend.train()\n",
        "\n",
        "    # Forward pass\n",
        "    output = model_weekend(X_train_weekday_tensor)\n",
        "    loss = criterion(output.squeeze(), y_train_weekday_tensor)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:  # Log every 10 epochs\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiiIaulmkTu7"
      },
      "source": [
        "# Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-XpEXALQkTu7"
      },
      "outputs": [],
      "source": [
        "# Convert 2023 Weekend test data to PyTorch tensor\n",
        "X_test_weekend_tensor = torch.tensor(X_test_weekend, dtype=torch.float32)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model_weekend.eval()\n",
        "\n",
        "# Make predictions for 2023 Weekend data\n",
        "with torch.no_grad():\n",
        "    y_pred_weekend = model_weekend(X_test_weekend_tensor).squeeze()\n",
        "\n",
        "# Inverse scale the predictions and actual values to the original scale\n",
        "y_pred_weekend_original = scaler_weekend.inverse_transform(\n",
        "    y_pred_weekend.numpy().reshape(-1, 1)).flatten()\n",
        "y_test_weekend_original = scaler_weekend.inverse_transform(\n",
        "    y_test_weekend.reshape(-1, 1)).flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv93_ToBkTu8"
      },
      "source": [
        "## Evaluate the Weekend model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "m6cx9EEWkTu8",
        "outputId": "94ab6c82-4b64-4b4f-a185-462ea92332a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "(0,)\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-e57b25a327bd>:12: RuntimeWarning: Mean of empty slice\n",
            "  y_test_weekend_original = np.nan_to_num(y_test_weekend_original, nan=np.nanmean(y_test_weekend_original))\n",
            "<ipython-input-22-e57b25a327bd>:13: RuntimeWarning: Mean of empty slice\n",
            "  y_pred_weekend_original = np.nan_to_num(y_pred_weekend_original, nan=np.nanmean(y_pred_weekend_original))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e57b25a327bd>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmae_weekend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_weekend_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_weekend_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mmse_weekend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_weekend_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_weekend_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mr2_weekend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_weekend_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_weekend_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.85\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \"\"\"\n\u001b[0;32m--> 216\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultioutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1088\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(y_pred_weekend_original)\n",
        "print(y_pred_weekend_original.shape)\n",
        "\n",
        "\n",
        "print(np.isnan(y_test_weekend_original).sum())\n",
        "print(np.isnan(y_pred_weekend_original).sum())\n",
        "\n",
        "y_test_weekend_original = np.nan_to_num(y_test_weekend_original, nan=np.nanmean(y_test_weekend_original))\n",
        "y_pred_weekend_original = np.nan_to_num(y_pred_weekend_original, nan=np.nanmean(y_pred_weekend_original))\n",
        "\n",
        "mask = ~np.isnan(y_test_weekend_original) & ~np.isnan(y_pred_weekend_original)\n",
        "y_test_weekend_original = y_test_weekend_original[mask]\n",
        "y_pred_weekend_original = y_pred_weekend_original[mask]\n",
        "\n",
        "\n",
        "mae_weekend = mean_absolute_error(y_test_weekend_original, y_pred_weekend_original)\n",
        "mse_weekend = mean_squared_error(y_test_weekend_original, y_pred_weekend_original)\n",
        "r2_weekend = r2_score(y_test_weekend_original, y_pred_weekend_original)\n",
        "\n",
        "print(f'MAE for 2023 Weekend data: {mae_weekend:.2f}')\n",
        "print(f'MSE for 2023 Weekend data: {mse_weekend:.2f}')\n",
        "print(f'R2 for 2023 Weekend data: {r2_weekend:.2f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "testing_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}