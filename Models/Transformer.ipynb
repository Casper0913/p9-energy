{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer (DTU DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022 Data\n",
      "   Year  Month  Hour  DayType     power\n",
      "0  2022      1     0  Weekday  0.943937\n",
      "1  2022      1     1  Weekday  0.955728\n",
      "2  2022      1     2  Weekday  0.772173\n",
      "3  2022      1     3  Weekday  0.530580\n",
      "4  2022      1     4  Weekday  0.333006\n",
      "   Year  Month  Hour  DayType     power\n",
      "0  2022      1     0  Weekend  0.680075\n",
      "1  2022      1     1  Weekend  0.739797\n",
      "2  2022      1     2  Weekend  0.605256\n",
      "3  2022      1     3  Weekend  0.440174\n",
      "4  2022      1     4  Weekend  0.310420\n",
      "\n",
      "2023 Data\n",
      "   Year  Month  Hour  DayType     power\n",
      "0  2023      1     0  Weekday  0.881067\n",
      "1  2023      1     1  Weekday  1.288525\n",
      "2  2023      1     2  Weekday  1.312552\n",
      "3  2023      1     3  Weekday  1.074686\n",
      "4  2023      1     4  Weekday  0.573104\n",
      "   Year  Month  Hour  DayType     power\n",
      "0  2023      1     0  Weekend  0.805268\n",
      "1  2023      1     1  Weekend  1.142235\n",
      "2  2023      1     2  Weekend  1.186799\n",
      "3  2023      1     3  Weekend  1.097171\n",
      "4  2023      1     4  Weekend  0.780017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_excel('../Dataset/AveragePower.xlsx')\n",
    "\n",
    "\n",
    "# Split the data into 2022 and 2023 based on the 'Year' column\n",
    "df_2022 = df[df['Year'] == 2022].reset_index(drop=True)\n",
    "df_2023 = df[df['Year'] == 2023].reset_index(drop=True)\n",
    "\n",
    "# Split the 2022 and 2023 data by 'DayType' (Weekday, Weekend)\n",
    "df_2022_weekday = df_2022[df_2022['DayType'] == 'Weekday'].reset_index(drop=True)\n",
    "df_2022_weekend = df_2022[df_2022['DayType'] == 'Weekend'].reset_index(drop=True)\n",
    "df_2023_weekday = df_2023[df_2023['DayType'] == 'Weekday'].reset_index(drop=True)\n",
    "df_2023_weekend = df_2023[df_2023['DayType'] == 'Weekend'].reset_index(drop=True)\n",
    "\n",
    "print(\"\\n2022 Data\");\n",
    "print(df_2022_weekday.head())\n",
    "print(df_2022_weekend.head())\n",
    "\n",
    "print(\"\\n2023 Data\")\n",
    "print(df_2023_weekday.head())\n",
    "print(df_2023_weekend.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_data(df): \n",
    "  # Encode 'Hour' using sine and cosine\n",
    "  df['Hour_sin'] = np.sin(2 * np.pi * df['Hour']/24)\n",
    "  df['Hour_cos'] = np.cos(2 * np.pi * df['Hour']/24)\n",
    "\n",
    "  # Encode 'month' using sine and cosine \n",
    "  df['Month_sin'] = np.sin(2 * np.pi * df['Month']/12)\n",
    "  df['Month_cos'] = np.cos(2 * np.pi * df['Month']/12)\n",
    "\n",
    "  # Scale 'Power' using StandardScaler\n",
    "  scaler = StandardScaler()\n",
    "  df['Power'] = scaler.fit_transform(df[['power']])\n",
    "\n",
    "  return df, scaler\n",
    "\n",
    "# Proprocess Weekday data and Weekend data for 2022\n",
    "df_2022_weekday, scaler_weekday = preprocess_data(df_2022_weekday)\n",
    "df_2022_weekend, scaler_weekend = preprocess_data(df_2022_weekend)\n",
    "\n",
    "# Proprocess Weekday data and Weekend data for 2023\n",
    "df_2023_weekday, _ = preprocess_data(df_2023_weekday)\n",
    "df_2023_weekend, _ = preprocess_data(df_2023_weekend)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Function to create sequences for the model\n",
    "def create_sequences(df, window_size):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "\n",
    "    # Ensure that the data is numeric before processing\n",
    "    # Convert all columns to numeric\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    for i in range(len(df) - window_size):\n",
    "        # Drop power column for features\n",
    "        seq = df.iloc[i:i + window_size].drop(columns=['Power']).values\n",
    "        # Target is the next hour's power value\n",
    "        label = df.iloc[i + window_size]['Power']\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Create sequences for a month (24 hours)\n",
    "sequence_length = 24\n",
    "\n",
    "# Create sequences for Weekday and Weekend data\n",
    "X_train_weekday, y_train_weekday = create_sequences(\n",
    "    df_2022_weekday, sequence_length)\n",
    "X_train_weekday = X_train_weekday.astype(np.float32)  # Ensure float32\n",
    "X_train_weekday = torch.tensor(X_train_weekday, dtype=torch.float32)\n",
    "X_train_weekday = np.nan_to_num(X_train_weekday, nan=0.0).astype(np.float32)\n",
    "X_train_weekend, y_train_weekend = create_sequences(df_2022_weekend, sequence_length)\n",
    "\n",
    "\n",
    "X_test_weekday, y_test_weekday = create_sequences(df_2023_weekday, sequence_length)\n",
    "X_test_weekend, y_test_weekend = create_sequences(df_2023_weekend, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PowerPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_layers, output_dim):\n",
    "        super(PowerPredictor, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # Ensure input features match d_model\n",
    "        # Map input features to d_model\n",
    "        self.fc_input = nn.Linear(input_dim, d_model)\n",
    "\n",
    "        # Transformer model\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model, nhead=nhead, num_encoder_layers=num_layers)\n",
    "\n",
    "        # Fully connected layer for output\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply fully connected layer to match input to d_model\n",
    "        # (batch_size, seq_len, input_dim) -> (batch_size, seq_len, d_model)\n",
    "        x = self.fc_input(x)\n",
    "\n",
    "        # Transformer expects input shape (seq_len, batch_size, feature_dim)\n",
    "        # (batch_size, seq_len, feature_dim) -> (seq_len, batch_size, feature_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        transformer_output = self.transformer(x, x)\n",
    "        # Use the last output to predict next value\n",
    "        out = self.fc(transformer_output[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 1.2632\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 45\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Log every 10 epochs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/testing_env/lib/python3.9/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = X_train_weekday.shape[2]  # Number of features (e.g., Hour, Month)\n",
    "d_model = 128  # Transformer model dimension\n",
    "nhead = 4  # Number of heads in MultiheadAttention\n",
    "num_layers = 2  # Number of Transformer layers\n",
    "output_dim = 1  # Single output value\n",
    "\n",
    "# Create model\n",
    "model_weekend = PowerPredictor(\n",
    "    input_dim, d_model, nhead, num_layers, output_dim)\n",
    "\n",
    "\n",
    "# Check data types and handle missing values\n",
    "assert X_train_weekday.dtype in [\n",
    "    np.float32, np.float64], \"X_train_weekday must be float32 or float64\"\n",
    "assert y_train_weekday.dtype in [\n",
    "    np.float32, np.float64], \"y_train_weekday must be float32 or float64\"\n",
    "\n",
    "X_train_weekday = np.nan_to_num(X_train_weekday, nan=0.0).astype(np.float32)\n",
    "y_train_weekday = y_train_weekday.astype(np.float32)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_weekday_tensor = torch.tensor(X_train_weekday, dtype=torch.float32)\n",
    "y_train_weekday_tensor = torch.tensor(y_train_weekday, dtype=torch.float32)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_weekend.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model_weekend.train()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model_weekend(X_train_weekday_tensor)\n",
    "    loss = criterion(output.squeeze(), y_train_weekday_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:  # Log every 10 epochs\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 2023 Weekend test data to PyTorch tensor\n",
    "X_test_weekend_tensor = torch.tensor(X_test_weekend, dtype=torch.float32)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_weekend.eval()\n",
    "\n",
    "# Make predictions for 2023 Weekend data\n",
    "with torch.no_grad():\n",
    "    y_pred_weekend = model_weekend(X_test_weekend_tensor).squeeze()\n",
    "\n",
    "# Inverse scale the predictions and actual values to the original scale\n",
    "y_pred_weekend_original = scaler_weekend.inverse_transform(\n",
    "    y_pred_weekend.numpy().reshape(-1, 1)).flatten()\n",
    "y_test_weekend_original = scaler_weekend.inverse_transform(\n",
    "    y_test_weekend.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Weekend model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "mae_weekend = mean_absolute_error(y_test_weekend_original, y_pred_weekend_original)\n",
    "mse_weekend = mean_squared_error(y_test_weekend_original, y_pred_weekend_original)\n",
    "r2_weekend = r2_score(y_test_weekend_original, y_pred_weekend_original)\n",
    "\n",
    "print(f'MAE for 2023 Weekend data: {mae_weekend:.2f}')\n",
    "print(f'MSE for 2023 Weekend data: {mse_weekend:.2f}')\n",
    "print(f'R2 for 2023 Weekend data: {r2_weekend:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
